{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410fa1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed55e2a4",
   "metadata": {},
   "source": [
    "# Data Reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1560bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=pd.read_csv(\"C:/Users/abira/Downloads/archive (1)/Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0becb8a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e6ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=pd.read_csv(\"C:/Users/abira/Downloads/archive (1)/Admission_Predict_Ver1.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab107a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55615d",
   "metadata": {},
   "source": [
    "\n",
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345db69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a4c74c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634f4acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa41b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1200f1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200.500000</td>\n",
       "      <td>316.807500</td>\n",
       "      <td>107.410000</td>\n",
       "      <td>3.087500</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.452500</td>\n",
       "      <td>8.598925</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.724350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.614301</td>\n",
       "      <td>11.473646</td>\n",
       "      <td>6.069514</td>\n",
       "      <td>1.143728</td>\n",
       "      <td>1.006869</td>\n",
       "      <td>0.898478</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.498362</td>\n",
       "      <td>0.142609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.750000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300.250000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  400.000000  400.000000   400.000000         400.000000  400.000000   \n",
       "mean   200.500000  316.807500   107.410000           3.087500    3.400000   \n",
       "std    115.614301   11.473646     6.069514           1.143728    1.006869   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    100.750000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    200.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    300.250000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    400.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "             LOR         CGPA    Research  Chance of Admit   \n",
       "count  400.000000  400.000000  400.000000        400.000000  \n",
       "mean     3.452500    8.598925    0.547500          0.724350  \n",
       "std      0.898478    0.596317    0.498362          0.142609  \n",
       "min      1.000000    6.800000    0.000000          0.340000  \n",
       "25%      3.000000    8.170000    0.000000          0.640000  \n",
       "50%      3.500000    8.610000    1.000000          0.730000  \n",
       "75%      4.000000    9.062500    1.000000          0.830000  \n",
       "max      5.000000    9.920000    1.000000          0.970000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "661dae9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>316.472000</td>\n",
       "      <td>107.192000</td>\n",
       "      <td>3.114000</td>\n",
       "      <td>3.374000</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>8.576440</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.72174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>11.295148</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.92545</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.14114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  500.000000  500.000000   500.000000         500.000000  500.000000   \n",
       "mean   250.500000  316.472000   107.192000           3.114000    3.374000   \n",
       "std    144.481833   11.295148     6.081868           1.143512    0.991004   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    125.750000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    250.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    375.250000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "            LOR         CGPA    Research  Chance of Admit   \n",
       "count  500.00000  500.000000  500.000000         500.00000  \n",
       "mean     3.48400    8.576440    0.560000           0.72174  \n",
       "std      0.92545    0.604813    0.496884           0.14114  \n",
       "min      1.00000    6.800000    0.000000           0.34000  \n",
       "25%      3.00000    8.127500    0.000000           0.63000  \n",
       "50%      3.50000    8.560000    1.000000           0.72000  \n",
       "75%      4.00000    9.040000    1.000000           0.82000  \n",
       "max      5.00000    9.920000    1.000000           0.97000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "287fdec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44904f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c71919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d80731a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9676977e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7293ca69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d04452fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.drop(columns=[\"Serial No.\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f082afa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62129a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "349970b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9e1d03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.472000</td>\n",
       "      <td>107.192000</td>\n",
       "      <td>3.114000</td>\n",
       "      <td>3.374000</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>8.576440</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.72174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.295148</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.92545</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.14114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE Score  TOEFL Score  University Rating         SOP       LOR   \\\n",
       "count  500.000000   500.000000         500.000000  500.000000  500.00000   \n",
       "mean   316.472000   107.192000           3.114000    3.374000    3.48400   \n",
       "std     11.295148     6.081868           1.143512    0.991004    0.92545   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.00000   \n",
       "25%    308.000000   103.000000           2.000000    2.500000    3.00000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.50000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.00000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.00000   \n",
       "\n",
       "             CGPA    Research  Chance of Admit   \n",
       "count  500.000000  500.000000         500.00000  \n",
       "mean     8.576440    0.560000           0.72174  \n",
       "std      0.604813    0.496884           0.14114  \n",
       "min      6.800000    0.000000           0.34000  \n",
       "25%      8.127500    0.000000           0.63000  \n",
       "50%      8.560000    1.000000           0.72000  \n",
       "75%      9.040000    1.000000           0.82000  \n",
       "max      9.920000    1.000000           0.97000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1d54c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research  \\\n",
       "min        290           92                  1  1.0  1.0  6.80         0   \n",
       "max        340          120                  5  5.0  5.0  9.92         1   \n",
       "\n",
       "     Chance of Admit  \n",
       "min             0.34  \n",
       "max             0.97  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Range of every feature\n",
    "range_ft = pd.DataFrame({\"GRE Score\": [df_2[\"GRE Score\"].min(), df_2[\"GRE Score\"].max()],\n",
    "                        \"TOEFL Score\": [df_2[\"TOEFL Score\"].min(), df_2[\"TOEFL Score\"].max()], \n",
    "                        \"University Rating\":[df_2[\"University Rating\"].min(), df_2[\"University Rating\"].max()], \n",
    "                        \"SOP\": [df_2[\"SOP\"].min(), df_2[\"SOP\"].max()],\n",
    "                        \"LOR\": [df_2[\"LOR \"].min(), df_2[\"LOR \"].max()],\n",
    "                        \"CGPA\": [df_2[\"CGPA\"].min(), df_2[\"CGPA\"].max()],\n",
    "                        \"Research\": [df_2[\"Research\"].min(), df_2[\"Research\"].max()],\n",
    "                        \"Chance of Admit\": [df_2[\"Chance of Admit \"].min(), df_2[\"Chance of Admit \"].max()]\n",
    "                        }, index=[\"min\", \"max\"])\n",
    "\n",
    "range_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e89e8342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8746ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0af610c4",
   "metadata": {},
   "source": [
    "y = df_2[\"Chance of Admit \"]\n",
    "X = df_2.drop(columns=[\"Chance of Admit \"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb0f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5416ddb",
   "metadata": {},
   "source": [
    "# Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58440bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d8d3b",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "436d5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation=\"relu\", input_dim=7))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e74a34ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                128       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273 (1.07 KB)\n",
      "Trainable params: 273 (1.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f6256f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 1s 15ms/step - loss: 0.2963 - val_loss: 0.1645\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1462 - val_loss: 0.0676\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0701 - val_loss: 0.0443\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0488 - val_loss: 0.0465\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.0402\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0338 - val_loss: 0.0306\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0240\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0190\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0158\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0130\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "#model Compilingng and fitting\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98bb72",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a0fde3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14921ee69a0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5nElEQVR4nO3dfXRV1YH//8+5zyEkVyCQgECMjAqIUgkKCYPWaY0y2mrb75hpp2jXaFtmtAMys2ZK0arMQ/Q7rUU7gjK1ZZjfEtL+0NH5FStxtRUoTGeZJtZaxzpVCWJiCA+5ebyP+/fHSW5yDeHkhiQnkvdrrbtIzt1333127k0+7L3PvpYxxggAAGAc87jdAAAAACcEFgAAMO4RWAAAwLhHYAEAAOMegQUAAIx7BBYAADDuEVgAAMC4R2ABAADjns/tBoyUVCql999/X3l5ebIsy+3mAACAITDGqK2tTbNmzZLHM/g4yjkTWN5//33NmTPH7WYAAIBhOHLkiGbPnj3o/edMYMnLy5Nkn3B+fr7LrQEAAEMRiUQ0Z86c9N/xwZwzgaV3Gig/P5/AAgDAR4zTcg4W3QIAgHGPwAIAAMY9AgsAABj3CCwAAGDcI7AAAIBxb1iBZcuWLSopKVEoFFJpaan2798/aNkDBw5oxYoVmjZtmnJycjR//nx95zvfGVBu9+7dWrhwoYLBoBYuXKhnn312OE0DAADnoKwDS3V1tdatW6eNGzeqrq5OK1eu1KpVq9TQ0HDa8rm5ubr77ru1b98+vfHGG7r33nt17733atu2bekyhw4dUmVlpVavXq1XX31Vq1ev1q233qpf/vKXwz8zAABwzrCMMSabByxbtkxLlizR1q1b08cWLFigW265RVVVVUOq47Of/axyc3P17//+75KkyspKRSIRvfDCC+kyN9xwg6ZMmaKdO3cOqc5IJKJwOKzW1lb2YQEA4CNiqH+/sxphicViqq2tVUVFRcbxiooKHTx4cEh11NXV6eDBg7rmmmvSxw4dOjSgzuuvv/6MdUajUUUikYwbAAA4N2UVWFpaWpRMJlVYWJhxvLCwUE1NTWd87OzZsxUMBrV06VLddddduvPOO9P3NTU1ZV1nVVWVwuFw+sbnCAEAcO4a1qLbD2+fa4xx3FJ3//79euWVV/TEE09o8+bNA6Z6sq1zw4YNam1tTd+OHDmS5VkAAICPiqw+S6igoEBer3fAyEdzc/OAEZIPKykpkSRddtll+uCDD/TAAw/o85//vCSpqKgo6zqDwaCCwWA2zQcAAB9RWY2wBAIBlZaWqqamJuN4TU2NysvLh1yPMUbRaDT9fVlZ2YA69+7dm1Wdo+V7+9/WA8+/rv9pYo0MAABuyfrTmtevX6/Vq1dr6dKlKisr07Zt29TQ0KA1a9ZIsqdqjh49qh07dkiSHn/8cc2dO1fz58+XZO/L8q1vfUtf+9rX0nWuXbtWV199tR5++GHdfPPNeu655/TSSy/pwIEDI3GOZ+XHrzWqruGUyudN0/wirj4CAMANWQeWyspKHT9+XJs2bVJjY6MWLVqkPXv2qLi4WJLU2NiYsSdLKpXShg0b9M4778jn82nevHl66KGH9NWvfjVdpry8XLt27dK9996r++67T/PmzVN1dbWWLVs2Aqd4dnpX0aSyuvgbAACMpKz3YRmvRmsfls9tPajawyf1xBeX6IZFM0esXgAAMEr7sExEnp4hlnMj1gEA8NFEYHFg9UwKMSUEAIB7CCxOekdYRGIBAMAtBBYHTAkBAOA+AouDvikhEgsAAG4hsDhw+MQBAAAwBggsDjw9iYUBFgAA3ENgcdA7wsKUEAAA7iGwDBF5BQAA9xBYHKSnhFxuBwAAExmBxQFTQgAAuI/A4iB9kRB5BQAA1xBYHPRNCZFYAABwC4HFQd+UkLvtAABgIiOwOLDYhwUAANcRWBz0rmFh0S0AAO4hsDiw0p/WDAAA3EJgceCx+LhmAADcRmBxwKJbAADcR2BxYKl30S2JBQAAtxBYHLCGBQAA9xFYHPRe1syUEAAA7iGwOOi9rJkpIQAA3ENgceCxnMsAAIDRRWBx0DclxAgLAABuIbA46JsScrUZAABMaAQWB+nPEnK5HQAATGQEFgd9G8cRWQAAcAuBxQFTQgAAuI/A4iD9WUIAAMA1BBYH6Skhdo4DAMA1BBYHbM0PAID7CCwO0lcJkVgAAHANgcVB7woWrhICAMA9BBYHTAkBAOA+AouD9FVCjLAAAOAaAouDvikhV5sBAMCERmBx0Lc1P4kFAAC3EFgc9G3N7247AACYyAgsDixxWTMAAG4jsDjwpK8SIrEAAOAWAosDLhICAMB9BBYHfTvdklgAAHALgcUBIywAALiPwOKgd9EtVwkBAOAeAosDi0W3AAC4bliBZcuWLSopKVEoFFJpaan2798/aNlnnnlG1113naZPn678/HyVlZXpxRdfzCizfft2WZY14Nbd3T2c5o0oD1NCAAC4LuvAUl1drXXr1mnjxo2qq6vTypUrtWrVKjU0NJy2/L59+3Tddddpz549qq2t1bXXXqtPfepTqquryyiXn5+vxsbGjFsoFBreWY2gvn1YSCwAALjFl+0DHnnkEd1xxx268847JUmbN2/Wiy++qK1bt6qqqmpA+c2bN2d8/0//9E967rnn9J//+Z+64oor0scty1JRUVG2zRl1fFozAADuy2qEJRaLqba2VhUVFRnHKyoqdPDgwSHVkUql1NbWpqlTp2Ycb29vV3FxsWbPnq2bbrppwAiMW/oua3a5IQAATGBZBZaWlhYlk0kVFhZmHC8sLFRTU9OQ6vj2t7+tjo4O3Xrrrelj8+fP1/bt2/X8889r586dCoVCWrFihd56661B64lGo4pEIhm30dD3ac0kFgAA3JL1lJDUN+rQyxgz4Njp7Ny5Uw888ICee+45zZgxI318+fLlWr58efr7FStWaMmSJfrud7+rxx577LR1VVVV6cEHHxxO87PClBAAAO7LaoSloKBAXq93wGhKc3PzgFGXD6uurtYdd9yhH/7wh/rkJz955kZ5PLryyivPOMKyYcMGtba2pm9HjhwZ+olkwcOUEAAArssqsAQCAZWWlqqmpibjeE1NjcrLywd93M6dO/WlL31JTz/9tG688UbH5zHGqL6+XjNnzhy0TDAYVH5+fsZtNPSOG3GVEAAA7sl6Smj9+vVavXq1li5dqrKyMm3btk0NDQ1as2aNJHvk4+jRo9qxY4ckO6zcdtttevTRR7V8+fL06ExOTo7C4bAk6cEHH9Ty5ct10UUXKRKJ6LHHHlN9fb0ef/zxkTrPYWNrfgAA3Jd1YKmsrNTx48e1adMmNTY2atGiRdqzZ4+Ki4slSY2NjRl7sjz55JNKJBK66667dNddd6WP33777dq+fbsk6dSpU/rKV76ipqYmhcNhXXHFFdq3b5+uuuqqszy9s5e+SohVLAAAuMYy58hcRyQSUTgcVmtr64hOD235+f/q//7kTf2f0tn61p8sHrF6AQDA0P9+81lCDvp2unW5IQAATGAEFgcePvwQAADXEVgcsOgWAAD3EVgc9O3DQmIBAMAtBJYhSpFXAABwDYHFQd9lzQAAwC0EFgfpRbdMCQEA4BoCi4O+rfldbQYAABMagcUBO90CAOA+AosDD5c1AwDgOgKLk54RlhSJBQAA1xBYHLCGBQAA9xFYHHi4rBkAANcRWBxYXNYMAIDrCCwOmBICAMB9BBYHTAkBAOA+AouTniEWrhICAMA9BBYHTAkBAOA+AosDpoQAAHAfgcUBVwkBAOA+AosDi635AQBwHYHFgYcPPwQAwHUEliFKpdxuAQAAExeBxYHFCAsAAK4jsDjwsIYFAADXEVgcWD07sRBYAABwD4HFQXqEhSkhAABcQ2BxYKW35ne3HQAATGQEFke9U0IkFgAA3EJgcdA3JQQAANxCYHHQe1kzU0IAALiHwOKg99OauUwIAAD3EFgceHp6iLgCAIB7CCwOevdhSTHCAgCAawgsTtjpFgAA1xFYHKQ/rZnAAgCAawgsDnoX3TIlBACAewgsDizLuQwAABhdBBYHTAkBAOA+AosDpoQAAHAfgcUJW/MDAOA6AouDvikhIgsAAG4hsDjonRIirwAA4B4Ci4PeDz8krwAA4B4CiwNPeqdbIgsAAG4hsDjo3YclRV4BAMA1BBZHvVNCJBYAANwyrMCyZcsWlZSUKBQKqbS0VPv37x+07DPPPKPrrrtO06dPV35+vsrKyvTiiy8OKLd7924tXLhQwWBQCxcu1LPPPjucpo04Dx9+CACA67IOLNXV1Vq3bp02btyouro6rVy5UqtWrVJDQ8Npy+/bt0/XXXed9uzZo9raWl177bX61Kc+pbq6unSZQ4cOqbKyUqtXr9arr76q1atX69Zbb9Uvf/nL4Z/ZCLHY6RYAANdZJsvVpMuWLdOSJUu0devW9LEFCxbolltuUVVV1ZDquPTSS1VZWalvfvObkqTKykpFIhG98MIL6TI33HCDpkyZop07dw6pzkgkonA4rNbWVuXn52dxRmf26/dO6dP/8gvNCod0cMMnRqxeAAAw9L/fWY2wxGIx1dbWqqKiIuN4RUWFDh48OKQ6UqmU2traNHXq1PSxQ4cODajz+uuvP2Od0WhUkUgk4zYarJ41LCy6BQDAPVkFlpaWFiWTSRUWFmYcLywsVFNT05Dq+Pa3v62Ojg7deuut6WNNTU1Z11lVVaVwOJy+zZkzJ4szGTorvTU/iQUAALcMa9Ft77qOXsaYAcdOZ+fOnXrggQdUXV2tGTNmnFWdGzZsUGtra/p25MiRLM5g6CwW3QIA4DpfNoULCgrk9XoHjHw0NzcPGCH5sOrqat1xxx360Y9+pE9+8pMZ9xUVFWVdZzAYVDAYzKb5w8KUEAAA7stqhCUQCKi0tFQ1NTUZx2tqalReXj7o43bu3KkvfelLevrpp3XjjTcOuL+srGxAnXv37j1jnWOlb5CHxAIAgFuyGmGRpPXr12v16tVaunSpysrKtG3bNjU0NGjNmjWS7Kmao0ePaseOHZLssHLbbbfp0Ucf1fLly9MjKTk5OQqHw5KktWvX6uqrr9bDDz+sm2++Wc8995xeeuklHThwYKTOc9g8XNYMAIDrsl7DUllZqc2bN2vTpk362Mc+pn379mnPnj0qLi6WJDU2NmbsyfLkk08qkUjorrvu0syZM9O3tWvXpsuUl5dr165d+sEPfqDLL79c27dvV3V1tZYtWzYCp3h2+rbmJ7EAAOCWrPdhGa9Gax+Wtz5o03Xf2afzJvlV/80K5wcAAIAhG5V9WCYidroFAMB9BBYHTAkBAOA+AosDLhICAMB9BBYH6auEXG4HAAATGYHFAVNCAAC4j8DioHenW/IKAADuIbA44MMPAQBwH4HFQd+UkLvtAABgIiOwOLD6hlgAAIBLCCwOPEwJAQDgOgKLg95Ft0wJAQDgHgKLg/SMEJcJAQDgGgKLA5awAADgPgKLA/ZhAQDAfQQWBx6r72umhQAAcAeBxUH6smax8BYAALcQWBz0G2BhhAUAAJcQWBx4+o2wEFcAAHAHgcVJvyEWPrEZAAB3EFgcWBmLbt1rBwAAExmBxUH/KSEAAOAOAouD/nGFKSEAANxBYHHAlBAAAO4jsDjgKiEAANxHYMkCU0IAALiDwOKAKSEAANxHYHGQcZUQgQUAAFcQWBxwlRAAAO4jsDiwWHQLAIDrCCwOPBlrWIgsAAC4gcDioP8IS4q8AgCAKwgsWTBMCgEA4AoCi5MXvq5/D1RpifU7FrEAAOASAouTo7Va6XlN06wIU0IAALiEwOLEsrvII8OUEAAALiGwOOkJLJYMO90CAOASAouT9AhLio3jAABwCYHFSc9lzR5GWAAAcA2BxUm/ERYCCwAA7iCwOGHRLQAAriOwOPF47X8YYQEAwDUEFie9IyyWYdEtAAAuIbA46X9Zs8tNAQBgoiKwOOm/hoXEAgCAKwgsTjKuEiKxAADgBgKLk/77sLjcFAAAJqphBZYtW7aopKREoVBIpaWl2r9//6BlGxsb9YUvfEGXXHKJPB6P1q1bN6DM9u3bZVnWgFt3d/dwmjey2JofAADXZR1YqqurtW7dOm3cuFF1dXVauXKlVq1apYaGhtOWj0ajmj59ujZu3KjFixcPWm9+fr4aGxszbqFQKNvmjTy25gcAwHVZB5ZHHnlEd9xxh+68804tWLBAmzdv1pw5c7R169bTlr/gggv06KOP6rbbblM4HB60XsuyVFRUlHEbF1h0CwCA67IKLLFYTLW1taqoqMg4XlFRoYMHD55VQ9rb21VcXKzZs2frpptuUl1d3RnLR6NRRSKRjNuoYKdbAABcl1VgaWlpUTKZVGFhYcbxwsJCNTU1DbsR8+fP1/bt2/X8889r586dCoVCWrFihd56661BH1NVVaVwOJy+zZkzZ9jPf0bpNSzsdAsAgFuGtejW6rlyppcxZsCxbCxfvlxf/OIXtXjxYq1cuVI//OEPdfHFF+u73/3uoI/ZsGGDWltb07cjR44M+/nPqCeweAksAAC4xpdN4YKCAnm93gGjKc3NzQNGXc6Gx+PRlVdeecYRlmAwqGAwOGLPOSir97OEmBICAMAtWY2wBAIBlZaWqqamJuN4TU2NysvLR6xRxhjV19dr5syZI1bnsPXbhyVFXgEAwBVZjbBI0vr167V69WotXbpUZWVl2rZtmxoaGrRmzRpJ9lTN0aNHtWPHjvRj6uvrJdkLa48dO6b6+noFAgEtXLhQkvTggw9q+fLluuiiixSJRPTYY4+pvr5ejz/++Aic4lnqtw8LlzUDAOCOrANLZWWljh8/rk2bNqmxsVGLFi3Snj17VFxcLMneKO7De7JcccUV6a9ra2v19NNPq7i4WO+++64k6dSpU/rKV76ipqYmhcNhXXHFFdq3b5+uuuqqszi1EcLW/AAAuM4y58hf4UgkonA4rNbWVuXn549cxf/feumVp/Sd+Oe04s5v6aqSqSNXNwAAE9xQ/37zWUJOekdYLKaEAABwC4HFSb99WFKsugUAwBUEFif9drpNMsICAIArCCxO+gUWBlgAAHAHgcVJ/31YSCwAALiCwOKk3xqWJIEFAABXEFic9PssIa4SAgDAHQQWJxlrWAgsAAC4gcDixGN/+KElo2TK5bYAADBBEVic9NuanxEWAADcQWBxwpQQAACuI7A4IbAAAOA6AouTnn1Y7MuaXW4LAAATFIHFSf8RFvZhAQDAFQQWJ0wJAQDgOgKLk97AYvHhhwAAuIXA4qTf1vxMCQEA4A4CixM+rRkAANcRWJz0Cyx8+CEAAO4gsDjhww8BAHAdgcVJ/zUsBBYAAFxBYHGSMSXkclsAAJigCCxO2IcFAADXEVicsNMtAACuI7A46beGhY3jAABwB4HFCSMsAAC4jsDihI3jAABwHYHFSTqwMCUEAIBbCCxO0mtYmBICAMAtBBYnliWJy5oBAHATgcUJG8cBAOA6AouT3sBisTU/AABuIbA46bfolsACAIA7CCxOPF77HxklWXQLAIArCCxO2IcFAADXEVic9Nuan8uaAQBwB4HFSf+rhFjDAgCAKwgsTtiHBQAA1xFYnPDhhwAAuI7A4qTfGpYkeQUAAFcQWJxkXCVEYgEAwA0EFidMCQEA4DoCi5N+O92ycRwAAO4gsDhJr2Fh4zgAANxCYHHSE1i8fJYQAACuIbA4sfgsIQAA3DaswLJlyxaVlJQoFAqptLRU+/fvH7RsY2OjvvCFL+iSSy6Rx+PRunXrTltu9+7dWrhwoYLBoBYuXKhnn312OE0beT0bx1kWVwkBAOCWrANLdXW11q1bp40bN6qurk4rV67UqlWr1NDQcNry0WhU06dP18aNG7V48eLTljl06JAqKyu1evVqvfrqq1q9erVuvfVW/fKXv8y2eSOv36JbAgsAAO6wjMnur/CyZcu0ZMkSbd26NX1swYIFuuWWW1RVVXXGx3784x/Xxz72MW3evDnjeGVlpSKRiF544YX0sRtuuEFTpkzRzp07h9SuSCSicDis1tZW5efnD/2EnDT+WnpypZrMFK07f6d2faVs5OoGAGCCG+rf76xGWGKxmGpra1VRUZFxvKKiQgcPHhxeS2WPsHy4zuuvv/6MdUajUUUikYzbqMjYOG50ngIAAJxZVoGlpaVFyWRShYWFGccLCwvV1NQ07EY0NTVlXWdVVZXC4XD6NmfOnGE//xn125qfjeMAAHDHsBbdWj0LUXsZYwYcG+06N2zYoNbW1vTtyJEjZ/X8gzesb4QlyRoWAABc4cumcEFBgbxe74CRj+bm5gEjJNkoKirKus5gMKhgMDjs5xwypoQAAHBdViMsgUBApaWlqqmpyTheU1Oj8vLyYTeirKxsQJ179+49qzpHTP+rhEgsAAC4IqsRFklav369Vq9eraVLl6qsrEzbtm1TQ0OD1qxZI8meqjl69Kh27NiRfkx9fb0kqb29XceOHVN9fb0CgYAWLlwoSVq7dq2uvvpqPfzww7r55pv13HPP6aWXXtKBAwdG4BTPUu8+LGwcBwCAa7IOLJWVlTp+/Lg2bdqkxsZGLVq0SHv27FFxcbEke6O4D+/JcsUVV6S/rq2t1dNPP63i4mK9++67kqTy8nLt2rVL9957r+677z7NmzdP1dXVWrZs2Vmc2gjJmBIisAAA4Ias92EZr0ZtH5aTh6VHL1eXCejm8/5f7b3nmpGrGwCACW5U9mGZkFh0CwCA6wgsTjz2hx+yDwsAAO4hsDhhHxYAAFxHYHHColsAAFxHYHHSG1gso1SSwAIAgBsILE6svi5KpVIuNgQAgImLwOKk/+cZGQILAABuILA46TfCYkzSxYYAADBxEVic9A8sTAkBAOAKAouTfoFFXCUEAIArCCxOMqaEGGEBAMANBBYnGSMsrGEBAMANBBYnBBYAAFxHYHFiefu+5rOEAABwBYHFSb99WFjDAgCAOwgsTixLRj2hhcACAIArCCxD0buOxaRkuLQZAIAxR2AZin6f2JxkHQsAAGOOwDIU/QILeQUAgLFHYBmKdGBJKcWUEAAAY47AMhQ9gcWyDIEFAAAXEFiGoufSZtawAADgDgLLUPSfEuLKZgAAxhyBZSgyFt0ywgIAwFgjsAxFvxGWJIEFAIAxR2AZAqv/CAtrWAAAGHMElqHw2B+AyD4sAAC4g8AyFP2mhOJJVt0CADDWCCxD0bsPi4yiCQILAABjjcAyFP3WsHTHky43BgCAiYfAMhQ9gcWvBIEFAAAXEFiGwp8jSQpacXURWAAAGHMElqHwBSVJQcXVHWcNCwAAY43AMhS+nhEWxRhhAQDABQSWofCHJEkhxVjDAgCACwgsQ+GzA0vQihNYAABwAYFlKHyMsAAA4CYCy1D0XCUUUkxdMRbdAgAw1ggsQ9FzlVBIcXUnGGEBAGCsEViGovcqISumrhiBBQCAsUZgGYr0VUJxRRlhAQBgzBFYhqLfoltGWAAAGHsElqHIuKyZRbcAAIw1AstQ9L9KiMuaAQAYcwSWoegdYWEfFgAAXEFgGYp0YGGnWwAA3DCswLJlyxaVlJQoFAqptLRU+/fvP2P5l19+WaWlpQqFQrrwwgv1xBNPZNy/fft2WZY14Nbd3T2c5o283quErBhrWAAAcEHWgaW6ulrr1q3Txo0bVVdXp5UrV2rVqlVqaGg4bfl33nlHf/zHf6yVK1eqrq5O3/jGN/RXf/VX2r17d0a5/Px8NTY2ZtxCodDwzmqk+VjDAgCAm3zZPuCRRx7RHXfcoTvvvFOStHnzZr344ovaunWrqqqqBpR/4oknNHfuXG3evFmStGDBAr3yyiv61re+pc997nPpcpZlqaioaJinMcp6drplSggAAHdkNcISi8VUW1urioqKjOMVFRU6ePDgaR9z6NChAeWvv/56vfLKK4rH4+lj7e3tKi4u1uzZs3XTTTeprq7ujG2JRqOKRCIZt1HT7yohAgsAAGMvq8DS0tKiZDKpwsLCjOOFhYVqamo67WOamppOWz6RSKilpUWSNH/+fG3fvl3PP/+8du7cqVAopBUrVuitt94atC1VVVUKh8Pp25w5c7I5lez4WMMCAICbhrXo1rKsjO+NMQOOOZXvf3z58uX64he/qMWLF2vlypX64Q9/qIsvvljf/e53B61zw4YNam1tTd+OHDkynFMZmn473caSKSWShBYAAMZSVmtYCgoK5PV6B4ymNDc3DxhF6VVUVHTa8j6fT9OmTTvtYzwej6688sozjrAEg0EFg8Fsmj98/r7LmiXpeEdMhfnjZEEwAAATQFYjLIFAQKWlpaqpqck4XlNTo/Ly8tM+pqysbED5vXv3aunSpfL7/ad9jDFG9fX1mjlzZjbNGz29VwlZcV3v+W81tY6Ty60BAJggsp4SWr9+vb73ve/p+9//vt544w3dc889amho0Jo1ayTZUzW33XZbuvyaNWt0+PBhrV+/Xm+88Ya+//3v66mnntLf/M3fpMs8+OCDevHFF/X222+rvr5ed9xxh+rr69N1us7XN5LzZGCzmk+cdLExAABMPFlf1lxZWanjx49r06ZNamxs1KJFi7Rnzx4VFxdLkhobGzP2ZCkpKdGePXt0zz336PHHH9esWbP02GOPZVzSfOrUKX3lK19RU1OTwuGwrrjiCu3bt09XXXXVCJziCOi5SqhXZ/M7kkrcaQsAABOQZXpXwH7ERSIRhcNhtba2Kj8/f+Sf4IFw+ssfXfId/cnn/3zknwMAgAlmqH+/+Syhobrs1vSXVuvpd/UFAACjg8AyVJ/7V71V8kVJUrD9PZcbAwDAxEJgyYJ36gWSpMnd77vbEAAAJhgCSxZyptsLbafFP3C5JQAATCwEliyEZ82TJM1Us9qjCZdbAwDAxEFgycKkKbMkSVPVpqZTnS63BgCAiYPAko1JUyVJXsvo+LHTf9gjAAAYeQSWbHj9arfyJEmtLSy8BQBgrBBYstTpP0+S1HGShbcAAIwVAkuWYsEpkqRoa7PLLQEAYOIgsGQplTNNkpRsP+ZySwAAmDgILFmyJs+wv+hscbchAABMIASWLAXz7cDi7zrucksAAJg4CCxZyptaJEmalDil7njS5dYAADAxEFiyFDrPHmGZqojeO9nlcmsAAJgYCCxZsnKnS5IKrFa9d5LdbgEAGAsElmzlny9Jmmmd0FECCwAAY4LAkq2wHVjyrC4da+HSZgAAxgKBJVuBXHX17Hbbdeywu20BAGCCILAMQyzXHmWJnyCwAAAwFggsw+CbMsf+ovWIUinjbmMAAJgACCzDkDPjAknSjNQxHWHhLQAAo47AMgyesD3Ccr7Vot990O5yawAAOPcRWIbjvLmSpLlWs373QZvLjQEA4NxHYBmOgoslSfOs9/VWU8TlxgAAcO4jsAzH1AuVsryabHXrRNO7brcGAIBzHoFlOHwBJcMXSJK8J36nJFcKAQAwqggsw+QrnC9JuiD1ng4f73C5NQAAnNsILMNkTb9EknSR9R5XCgEAMMoILMN1/hJJ0pWe33GlEAAAo4zAMlzFK2Rk6SLPUR1+93/dbg0AAOc0AstwTZqqzmmLJEmh9w7KGBbeAgAwWggsZyF48bWSpMXxV3X4OFv0AwAwWggsZ8E37xpJUrn3ddW+e8Ll1gAAcO4isJyNuWVKWj7Ntlr0+uuvut0aAADOWQSWsxHIVeeMKyRJnnd+qngy5XKDAAA4NxFYzlLuZZ+WJF2f2q9Dvz/ucmsAADg3EVjOkufy/6OULF3p+Z1qfnHI7eYAAHBOIrCcrfxZ6pp9tSTpkrf/TUdOcLUQAAAjjcAyAnI/+beSpFs9P9O2Z37CniwAAIwwAstIuOAP1TH3WgWspFY33KtH//O/lGABLgAAI4bAMkJy/+RJdQYKdLHnqG555Xb94+bNOvC7Zq4cAgBgBFjmHJm/iEQiCofDam1tVX5+vjuNOPamOp/6tCZ1N0mSGlLT9TPPcsVnXanc8xfqgosWauGcGcoL+uTxWO60EQCAcWSof78JLCOt65Q6X6qSVff/KCfVnnFX0lhq1DSdUr5a/QVSIE+J8FwlJxXKkztN/rwCBfKna1J4hoLhAgWDOZqSG1BuwCvLIuAAAM49BBa3xTqV+p8f6/jrP5V5r1Z5XUeUk8ruCqI2k6OTZrJOKk+tVr7aPPnq8IbV7c2T8QUV9YeV8Ocr4ctVyj9JyUC+4sGw/L6AFMyVx5ejYMCrgNejoN+roNejgM+++TyWvB5LHo8lr2XJ57Hk93kU8Hrk93oU8FmyLEuWJI9lyee1FPB65PN65Pda8ns9ShmjeNLIY0k+j0dej10Po0cAcA4yRhqF/zwTWMYbY6T2D9Td8q5am4+o/cQHOnWiWd7WBvmjxxWMnlIocUqTk63KM23y6uzXvsSMV+3KUadC6jJBdSmgLgXVbex/uxRQlwko2nO8q+d4twKZ5RWQkaWA4mo2UxSTT3F5FTc+JeRTTF7FZX/tV0JBK66YJySPxyuPxytjeZRISfFkSn6vRyG/VyGfR36fR5ZkByNL6XBkWb3/WvJ6+r62u9EoZYxSKSlljIyx//V6LOUGffJ5LKVf0EYyPd/Fk0bJlFGO3yu/z67LkpV+7/WGs5QxiiVSiiVTiiVSmpobUCJp1BFLKMfv1aSAV4mUXVciaRRPpdL15oV86fbbtdnv7fT3Vl+bUqmef4390lD6a6NEyuhUZ1x+r6VJAZ9yAl75vVb6nO2b/XUyZfeB32spnONXPGkUT6aUMlIyldLxjphmT8lR0OeVMSbdlx6rr697X54pY/dWyhip53upr/8//HvK9Otf+7xsdrC1FE2klEqZnvYPvlxusF9Bg/1iMkY60RlTXtDum1TKqDOWlN/nkb/n52/69U88aZQT8CjH71VXPCmvZSnSnVDA69F5uX4lk6bvZ5oySqZSMkYK+j0K+bzyeT32efaco+l53fU+T0t7VIlkUpbHI2OMJgV8yg14FQp4lUwaxZIpxZMpxeNJzT32Ux3zzNAHkxdoUsCrSUG7bNDnlVHv61kZz5dKGRV0/V4zPviFfuy/TpdeOEeRrrg6Ywn5vR51x1PKCXiUG/ApmkhpctCngM+jzlgyvfg/mGhX3BeS5fFLPT97j1Jq64rKWH7lhXzqiifT78+gz6Nkyn6t+b32f0Z632/G9L1uTSqhlOWVSaXS958fqdep4Cz5psxWe9Ru46SAVwGfxz6/nv5N9XsN9b6e+9dvv8+NWjpimpEX7DnXpLp72jljsl8t7TF5PB7NyA/JGKOuzk51Gp/yQ34F/R5F4yn5fR61dccVTxj5PFLA55Wv5z9dAa9HlkkolkioK+lVMtqh7qRX4ck56d8boYBX8a52dXS0K5Q/XZOC3vRjJSnSHVdRfkgpYxRNpPq9juzfS0GfXa4zltR5OX61RxPy9vyHsfc/eTJG7Z3d8gYCCvm86feoNxXTyc6EEh0ntODILjUW/ZE6p1+uoK+3P03Pe90oaYyCXqk7YdTd3a3crkZ15xQp5QvKGKNwjl/nTQrYr8VkSvFESvGe32OWJU0OeKWOFnUav7yBkHy+gPxWQqmOEzrpmaqiw8+p+P09Ct32I00P5w76fh6OUQ0sW7Zs0T//8z+rsbFRl156qTZv3qyVK1cOWv7ll1/W+vXr9frrr2vWrFn627/9W61ZsyajzO7du3Xffffp97//vebNm6d//Md/1Gc+85kht2ncB5ZspFJS9ymZzuOKRo6pO3JMibYWJduPy3S0SN2nlIzH5Imeki96St5Ep7yJTgXjEQUTEVmD/qofW0ljyWsZdZqgovJLklKylJJHyZ6bkaWksb/uPd7//oyvjUfJnscbWT33WwooIUtGXQoqqLji8mqy1a02M0l+JRSVXx6lFFRcEU2SX0l5lZRXKXUqqFxFdUJ58vfWY4KaYZ1STD75ldRx5SthvApZMYUUU1IetZpcBa24rvL8j1pNrj4wU3RC+UoYj3xWSl4l5et5jsx/k+n7o8avd8xMGVmyZGTJyKuUzrda1GimyWclNF2tet9MS5fxyMhjmXR5IylXUc2wTuodM1P2nzhLCeNVUh4l5JUlo8lWl9pNjgJKKGjFlJBP+epQm3IkWYoav/xKKMeKSrIUMTkKWglJUtx4e1ruUUgx5VpdCiihuHyK9QTVOVazIiZXKVnqVFA+JdVhQppsdSmqgAKKy6+kEvIqIY+S8srTr296fyYdCsmnpKLyy6uUukxQ51ntisurqAKKGZ9mW8cUl08nlGcHXvX2h/11Ql7N1AkFrZhaTa7mWs06agoUk0+tytWl1mFNsdrUbnJkyWiSFdVhU6j3zHTlq1MXWu8rJY+i8uuoKVBSHp2ndhlZimiS8tRph3oFFVJcc60PNNdq1jET1ltmtqZZrUrKq3aTow6FlJKlEqtJF1nvKWAlFTdevZhaqqASmm016z0zXZKlfKtDEZMrr5Lp17dXKRlJyz1vaLLVLUk6aqbpfTNNXSaomHyaarXJkhSTTzHjU0x+5Vrdmq5TapX9h2WJ53/VaKbq3VSRZlrH1WBmaL7niMJq1xtmrhLyKaiY/EqqVbmaojb7Pdzz84rJr4S8KlCrYvLppMlToXVSJVaT/tfMUoHVKr+SOmkma67nmJLG0mFTmH6/5SiqpLxqMWFd6nlXSXn0rilSvjrUorAsGc3UCQWsuHLVrf81sxRQUiFFFbASajH5siQVWK06YfLUqZAWWIclWXrTzNZU2f/Ju8DzgQ6nZuiE8jVVEXUqpHaFNFn2a3a21aKULLUrRxEzSR0K6QLrAwUV1zumSBdZ7ykhn05qsmLGp6gCisunC6wmhRTT22Zmz++M7p73l0/TrZM6ZfLk7Xl9e5VSvtWhfHXpfTNVXQppkroVtjrUoZCmqk0nlKd8daTfV2F1yG8lddRMs1+TiiolS3nqUkJe+ZSU30oqanx628yUVyl5lZKn91/LyKekpuuUjuk85SiqsNWppLHUonDPu0Ppvw2WpKmK6KQma7K61aWA/Eoqz+pK//6OmBxNUlQ+K6Wo8StoxSVJDSse0tzr/mJE/1aMWmCprq7W6tWrtWXLFq1YsUJPPvmkvve97+m3v/2t5s6dO6D8O++8o0WLFunLX/6yvvrVr+oXv/iF/vIv/1I7d+7U5z73OUnSoUOHtHLlSv393/+9PvOZz+jZZ5/VN7/5TR04cEDLli0b0RM+56V6RmZi7VI0IkXbpViHlOiS4l1SvHOQf7tPc6zf1yYpWV6ZjmNSKi4lE1IyJisVd/d8AQCjLimvXiy4XfP/5H5dWHjeiNY9aoFl2bJlWrJkibZu3Zo+tmDBAt1yyy2qqqoaUP7v/u7v9Pzzz+uNN95IH1uzZo1effVVHTpkb2VfWVmpSCSiF154IV3mhhtu0JQpU7Rz584htYvA4hJjpJQdXpSMSx6vZHmkRNT+3rKkaJtdRpJMSkol7QBkUnbAMsm+Y+l/BzluTM/Xqb46PPbojRLdki9ot8Wfawc2X8g+blmSN2CHN49P8vrtdkbbpECu1HVS8gbteuIdUihsP483IHUetx/vy7HrTyWk7oh9LK/IDnSWx65DsuvvvXl9md97fHYfeXxS5wmp9Yj9WFl9c8OTZ0jtzZLllXKnSR3H7f8Spct5euaZPH39MqnAbqfHa9eRStj3pRJ2nwUn2+HVF7T7JBWX/JPs8/d4pURM8gXsY6mkHXi9Aft5kvG++vw5UmCyXTYZt/s6EZVyC+y+9fqlWKddZ7RdyjnP7h+vv+d5E331fbg/PD6pu9V+3kS3/X28Q8qZav+cE912sJ40VZKxn8ey+vVdT/+l4lLoPPu5O45Jk6ZJbR/Ybe6OSLnTJX/I7pec8+znaXnLbr8vJE2/2O77rpP2442Rgnk97Ttlf52I2mHe65emXCDlz5Zafid1nbDrNym7b2MdPc8zRZpaIp1XLDUclCLv2/XlzZTa7asKlTPFPn/La5+PSdlfy0jBfOnCa6Tjv7f7r/0Duz8S3Xb/eP0977men4c3IIXP7ykXk85fYp9jNCLlzpDaGu3nm3KBdPJd+7n8OfbPouO4/fP0eHt+Xj3v71S852eRtMuE8qXz5kqtR+1+lOzXYNHl0qkGu22xdvt9FZhkvw46T0j5M+33bGeL/Vrq7ePJM+xzC+Ta9fhz7NejNyC1vW/3xeQZUkeL/bo4r9huX1uT/X6NdUgFF0uR9+y+z51hl4u223V6A1L++fZ7Mtpm37oj9nsjmG/XU3CRfR7RNrsfE91SMioFw1JeoXTibbs//Tk9r8me1340Ytff+zswkGv378nDdn/5Qva5dJ+yXytdJ+3XYO9rN9TzOjz5bt/7MBmz60nG7XYWXSY1vWb3qcfb8zrx9H3t8dg/n45j9vGiy+z+bnt/4HtExu6zzhN2OxNRu57z5trPZVJSR7P93uk9j8kzet57I2+of7992VQai8VUW1urr3/96xnHKyoqdPDgwdM+5tChQ6qoqMg4dv311+upp55SPB6X3+/XoUOHdM899wwos3nz5myaBzdYlv3L0uvPPB7oN8c5ecbYtgnI1oUfP/s6ZswfWrmFNw//OWYvHf5jp19y+uNFi4ZfpyTNWDDwWP7Ms6tzgNKhF51+8fCeYublzmXOGziLcEZTLsiufF7hme+fc+UQnrM4s74z1Xm69k2ePrAtQ31tj7KsAktLS4uSyaQKCzM7oLCwUE1NTad9TFNT02nLJxIJtbS0aObMmYOWGaxOSYpGo4pGo+nvI5FINqcCAAA+Qoa10+2H9wQxxpxxn5DTlf/w8WzrrKqqUjgcTt/mzJkz5PYDAICPlqwCS0FBgbxe74CRj+bm5gEjJL2KiopOW97n82natGlnLDNYnZK0YcMGtba2pm9HjhzJ5lQAAMBHSFaBJRAIqLS0VDU1NRnHa2pqVF5eftrHlJWVDSi/d+9eLV26VH6//4xlBqtTkoLBoPLz8zNuAADg3JTVGhZJWr9+vVavXq2lS5eqrKxM27ZtU0NDQ3pflQ0bNujo0aPasWOHJPuKoH/5l3/R+vXr9eUvf1mHDh3SU089lXH1z9q1a3X11Vfr4Ycf1s0336znnntOL730kg4cODBCpwkAAD7Ksg4slZWVOn78uDZt2qTGxkYtWrRIe/bsUXGxvTK5sbFRDQ0N6fIlJSXas2eP7rnnHj3++OOaNWuWHnvssfQeLJJUXl6uXbt26d5779V9992nefPmqbq6esh7sAAAgHMbW/MDAADXDPXv97CuEgIAABhLBBYAADDuEVgAAMC4R2ABAADjHoEFAACMewQWAAAw7mW9D8t41Xt1Nh+CCADAR0fv322nXVbOmcDS1tYmSXwIIgAAH0FtbW0Kh8OD3n/ObByXSqX0/vvvKy8v74yf8pytSCSiOXPm6MiRI2xIN8ro67FBP48N+nns0NdjY7T62RijtrY2zZo1Sx7P4CtVzpkRFo/Ho9mzZ49a/XzA4tihr8cG/Tw26OexQ1+PjdHo5zONrPRi0S0AABj3CCwAAGDcI7A4CAaDuv/++xUMBt1uyjmPvh4b9PPYoJ/HDn09Ntzu53Nm0S0AADh3McICAADGPQILAAAY9wgsAABg3COwAACAcY/A4mDLli0qKSlRKBRSaWmp9u/f73aTPlL27dunT33qU5o1a5Ysy9J//Md/ZNxvjNEDDzygWbNmKScnRx//+Mf1+uuvZ5SJRqP62te+poKCAuXm5urTn/603nvvvTE8i/GvqqpKV155pfLy8jRjxgzdcsstevPNNzPK0Ndnb+vWrbr88svTG2eVlZXphRdeSN9PH4+OqqoqWZaldevWpY/R1yPjgQcekGVZGbeioqL0/eOqnw0GtWvXLuP3+82//uu/mt/+9rdm7dq1Jjc31xw+fNjtpn1k7Nmzx2zcuNHs3r3bSDLPPvtsxv0PPfSQycvLM7t37zavvfaaqaysNDNnzjSRSCRdZs2aNeb88883NTU15le/+pW59tprzeLFi00ikRjjsxm/rr/+evODH/zA/OY3vzH19fXmxhtvNHPnzjXt7e3pMvT12Xv++efNj3/8Y/Pmm2+aN99803zjG98wfr/f/OY3vzHG0Mej4b//+7/NBRdcYC6//HKzdu3a9HH6emTcf//95tJLLzWNjY3pW3Nzc/r+8dTPBJYzuOqqq8yaNWsyjs2fP998/etfd6lFH20fDiypVMoUFRWZhx56KH2su7vbhMNh88QTTxhjjDl16pTx+/1m165d6TJHjx41Ho/H/OQnPxmztn/UNDc3G0nm5ZdfNsbQ16NpypQp5nvf+x59PAra2trMRRddZGpqasw111yTDiz09ci5//77zeLFi09733jrZ6aEBhGLxVRbW6uKioqM4xUVFTp48KBLrTq3vPPOO2pqasro42AwqGuuuSbdx7W1tYrH4xllZs2apUWLFvFzOIPW1lZJ0tSpUyXR16MhmUxq165d6ujoUFlZGX08Cu666y7deOON+uQnP5lxnL4eWW+99ZZmzZqlkpIS/emf/qnefvttSeOvn8+ZDz8caS0tLUomkyosLMw4XlhYqKamJpdadW7p7cfT9fHhw4fTZQKBgKZMmTKgDD+H0zPGaP369frDP/xDLVq0SBJ9PZJee+01lZWVqbu7W5MnT9azzz6rhQsXpn8508cjY9euXaqtrdUrr7wy4D5ezyNn2bJl2rFjhy6++GJ98MEH+od/+AeVl5fr9ddfH3f9TGBxYFlWxvfGmAHHcHaG08f8HAZ3991369e//rUOHDgw4D76+uxdcsklqq+v16lTp7R7927dfvvtevnll9P308dn78iRI1q7dq327t2rUCg0aDn6+uytWrUq/fVll12msrIyzZs3T//2b/+m5cuXSxo//cyU0CAKCgrk9XoHJMTm5uYBaRPD07sS/Ux9XFRUpFgsppMnTw5aBn2+9rWv6fnnn9fPfvYzzZ49O32cvh45gUBAf/AHf6ClS5eqqqpKixcv1qOPPkofj6Da2lo1NzertLRUPp9PPp9PL7/8sh577DH5fL50X9HXIy83N1eXXXaZ3nrrrXH3miawDCIQCKi0tFQ1NTUZx2tqalReXu5Sq84tJSUlKioqyujjWCyml19+Od3HpaWl8vv9GWUaGxv1m9/8hp9DP8YY3X333XrmmWf005/+VCUlJRn309ejxxijaDRKH4+gT3ziE3rttddUX1+fvi1dulR/9md/pvr6el144YX09SiJRqN64403NHPmzPH3mh7RJbznmN7Lmp966inz29/+1qxbt87k5uaad9991+2mfWS0tbWZuro6U1dXZySZRx55xNTV1aUvDX/ooYdMOBw2zzzzjHnttdfM5z//+dNeMjd79mzz0ksvmV/96lfmj/7oj7g08UP+4i/+woTDYfPzn/884/LEzs7OdBn6+uxt2LDB7Nu3z7zzzjvm17/+tfnGN75hPB6P2bt3rzGGPh5N/a8SMoa+Hil//dd/bX7+85+bt99+2/zXf/2Xuemmm0xeXl7679x46mcCi4PHH3/cFBcXm0AgYJYsWZK+TBRD87Of/cxIGnC7/fbbjTH2ZXP333+/KSoqMsFg0Fx99dXmtddey6ijq6vL3H333Wbq1KkmJyfH3HTTTaahocGFsxm/TtfHkswPfvCDdBn6+uz9+Z//efr3wfTp080nPvGJdFgxhj4eTR8OLPT1yOjdV8Xv95tZs2aZz372s+b1119P3z+e+tkyxpiRHbMBAAAYWaxhAQAA4x6BBQAAjHsEFgAAMO4RWAAAwLhHYAEAAOMegQUAAIx7BBYAADDuEVgAAMC4R2ABAADjHoEFAACMewQWAAAw7hFYAADAuPf/A6g0POC32YQZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecf32137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#Model prediction\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62e20afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8911578], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e41170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score is:  0.8019696288795019\n",
      "Mean Absolute Error is:  0.04727446545362473\n"
     ]
    }
   ],
   "source": [
    "#Model PErformance\n",
    "print(\"R2 Score is: \", r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error is: \", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd2c601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
